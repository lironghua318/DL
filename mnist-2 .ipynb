{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mnist-神经网络**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)#读取数据\n",
    "#mnist.train.images是一个55000 * 784维的矩阵, mnist.train.labels是一个55000 * 10维的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "trX,trY,teX,teY = mnist.train.images,mnist.train.labels,mnist.test.images,mnist.test.labels\n",
    "print(trX.shape)\n",
    "print(trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(teX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX = trX.reshape(-1,28,28,1)\n",
    "teX = teX.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS AND OUTPUTS\n",
    "x = tf.placeholder(tf.float32, [None, 28,28,1]) # 用placeholder先占地方，样本个数不确定为None\n",
    "y = tf.placeholder(tf.float32, [None,10 ]) # 用placeholder先占地方，样本个数不确定为None\n",
    "p_keep_conv = tf.placeholder(tf.float32) #dopout参数\n",
    "p_keep_hidden = tf.placeholder(tf.float32) #dropout参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK READY\n"
     ]
    }
   ],
   "source": [
    "# w1=tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev=0.1))\n",
    "# w2=tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=0.1))\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape,stddev=0.1))\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=1.0 / 5000)\n",
    "\n",
    "w4 = tf.get_variable(\n",
    "        name=\"w4\",\n",
    "        regularizer=regularizer,\n",
    "        initializer=tf.random_normal([128*4*4, 625], stddev=0.1))\n",
    "\n",
    "weights = {\n",
    "    'w1': init_weights([3,3,1,32]),\n",
    "    'w2': init_weights([3,3,32,64]),\n",
    "    'w3': init_weights([3,3,64,128]),\n",
    "    \n",
    "    \n",
    "    \n",
    "    'w4': w4,#按照高斯分布初始化权重\n",
    "    'out': init_weights([625,10])\n",
    "}\n",
    "biases = {\n",
    "    'b1':tf.Variable(tf.constant(0.1,shape=[32])),\n",
    "    'b2':tf.Variable(tf.constant(0.1,shape=[64])),\n",
    "    'b3':tf.Variable(tf.constant(0.1,shape=[128])),\n",
    "    'b4': tf.Variable(tf.constant(0.1,shape=[625])),\n",
    "    'out': tf.Variable(tf.constant(0.1,shape=[10]))\n",
    "}\n",
    "print(\"NETWORK READY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加入L2正则**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.add_to_collection(tf.GraphKeys.WEIGHTS,w4)\n",
    "# regularizer = tf.contrib.layers.l2_regularizer(scale=1.0 / 50000)\n",
    "# print(regularizer)\n",
    "reg_term = tf.contrib.layers.apply_regularization(regularizer)\n",
    "\n",
    "# loss = (tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_, logits=z_3)) +\n",
    "#         reg_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model (X,weights,biases,p_keep_conv,p_keep_hidden):\n",
    "    #第一组卷积层及池化层，最后dropout部分神经元\n",
    "    l1a = tf.nn.selu(tf.nn.conv2d(X,weights['w1'],strides=[1,1,1,1],padding = 'SAME')+biases['b1'])\n",
    "    l1 = tf.nn.max_pool(l1a,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    l1 = tf.nn.dropout(l1,p_keep_conv)\n",
    "    \n",
    "    #第二组卷积层及池化层，最后dropout部分神经元\n",
    "    l2a = tf.nn.selu(tf.nn.conv2d(l1,weights['w2'],strides=[1,1,1,1],padding = 'SAME')+biases['b2'])\n",
    "    l2 = tf.nn.max_pool(l2a,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    l2 = tf.nn.dropout(l2,p_keep_conv)\n",
    "   \n",
    "    #第三组卷积层及池化层，最后dropout部分神经元\n",
    "    l3a = tf.nn.selu(tf.nn.conv2d(l2,weights['w3'],strides=[1,1,1,1],padding = 'SAME')+biases['b3'])\n",
    "    l3 = tf.nn.max_pool(l3a,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    l3 = tf.nn.dropout(l3,p_keep_conv)\n",
    "    l3 = tf.reshape(l3,[-1,w4.get_shape().as_list()[0]])\n",
    "    \n",
    "    #全连接层的隐层\n",
    "    layer_1 = tf.nn.selu(tf.add(tf.matmul(l3, weights['w4']), biases['b4']))\n",
    "    layer_1 = tf.nn.dropout(layer_1,p_keep_hidden)\n",
    "    \n",
    "    #输出层\n",
    "    l_out = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "    \n",
    "    return l_out\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**隐层的激活函数尝试用RELU，输出层用softmax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-e4e494445a42>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "FUNCTIONS READY\n"
     ]
    }
   ],
   "source": [
    "pred = model(x, weights, biases,p_keep_conv,p_keep_hidden) # 前向传播的预测值\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)+ reg_term) # 交叉熵损失函数，参数分别为预测值pred和实际label值y，reduce_mean为求平均loss\n",
    "optm = tf.train.RMSPropOptimizer(0.001,0.9).minimize(cost) # 梯度下降优化器\n",
    "corr = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1)) # tf.equal()对比预测值的索引和实际label的索引是否一样，一样返回True，不一样返回False\n",
    "accr = tf.reduce_mean(tf.cast(corr, tf.float32)) # 将pred即True或False转换为1或0,并对所有的判断结果求均值\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "print(\"FUNCTIONS READY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上面神经网络结构定义好之后，下面定义一些超参数\n",
    "training_epochs = 100 # 所有样本迭代100次\n",
    "batch_size = 200 # 每进行一次迭代选择100个样本\n",
    "test_size = 256\n",
    "#display_step = 1\n",
    "# # LAUNCH THE GRAPH\n",
    "# sess = tf.Session() # 定义一个Session\n",
    "# sess.run(init) # 在sess里run一下初始化操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/100 cost: 4.712321234 TRAIN ACCURACY: 0.965 TEST ACCURACY: 0.898\n",
      "time: 208.72961354255676\n",
      "Epoch: 002/100 cost: 1.396958885 TRAIN ACCURACY: 0.965 TEST ACCURACY: 0.941\n",
      "time: 213.8066327571869\n",
      "Epoch: 003/100 cost: 1.074216613 TRAIN ACCURACY: 0.985 TEST ACCURACY: 0.945\n",
      "time: 198.86918425559998\n",
      "Epoch: 004/100 cost: 0.834599558 TRAIN ACCURACY: 0.980 TEST ACCURACY: 0.961\n",
      "time: 198.89280557632446\n",
      "Epoch: 005/100 cost: 0.636503658 TRAIN ACCURACY: 0.970 TEST ACCURACY: 0.945\n",
      "time: 199.29577803611755\n",
      "Epoch: 006/100 cost: 0.484624510 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.961\n",
      "time: 197.94662046432495\n",
      "Epoch: 007/100 cost: 0.375777249 TRAIN ACCURACY: 0.980 TEST ACCURACY: 0.957\n",
      "time: 201.15610456466675\n",
      "Epoch: 008/100 cost: 0.293136587 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.980\n",
      "time: 199.25197315216064\n",
      "Epoch: 009/100 cost: 0.236211415 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.965\n",
      "time: 197.11867666244507\n",
      "Epoch: 010/100 cost: 0.191484808 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.969\n",
      "time: 196.01526546478271\n",
      "Epoch: 011/100 cost: 0.162262779 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.980\n",
      "time: 196.8179919719696\n",
      "Epoch: 012/100 cost: 0.140592338 TRAIN ACCURACY: 0.980 TEST ACCURACY: 0.973\n",
      "time: 196.89879655838013\n",
      "Epoch: 013/100 cost: 0.122457563 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
      "time: 194.7202980518341\n",
      "Epoch: 014/100 cost: 0.111575918 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
      "time: 195.18477511405945\n",
      "Epoch: 015/100 cost: 0.101582346 TRAIN ACCURACY: 0.980 TEST ACCURACY: 0.977\n",
      "time: 194.17691564559937\n",
      "Epoch: 016/100 cost: 0.095880282 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.988\n",
      "time: 195.0981719493866\n",
      "Epoch: 017/100 cost: 0.089731355 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.980\n",
      "time: 194.9509723186493\n",
      "Epoch: 018/100 cost: 0.081986406 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.977\n",
      "time: 195.031268119812\n",
      "Epoch: 019/100 cost: 0.082369758 TRAIN ACCURACY: 0.985 TEST ACCURACY: 0.984\n",
      "time: 196.81258511543274\n",
      "Epoch: 020/100 cost: 0.077925515 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.973\n",
      "time: 194.13895058631897\n",
      "Epoch: 021/100 cost: 0.075514228 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
      "time: 193.93680882453918\n",
      "Epoch: 022/100 cost: 0.073353367 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.980\n",
      "time: 193.6325809955597\n",
      "Epoch: 023/100 cost: 0.071482874 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.973\n",
      "time: 192.091539144516\n",
      "Epoch: 024/100 cost: 0.070856013 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
      "time: 192.48212099075317\n",
      "Epoch: 025/100 cost: 0.071453776 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
      "time: 192.79103565216064\n",
      "Epoch: 026/100 cost: 0.067744820 TRAIN ACCURACY: 0.985 TEST ACCURACY: 0.977\n",
      "time: 200.7392373085022\n",
      "Epoch: 027/100 cost: 0.068039859 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.980\n",
      "time: 202.47152853012085\n",
      "Epoch: 028/100 cost: 0.068082741 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
      "time: 212.18765902519226\n",
      "Epoch: 029/100 cost: 0.068216553 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
      "time: 214.35138058662415\n",
      "Epoch: 030/100 cost: 0.067132999 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.988\n",
      "time: 205.2883038520813\n",
      "Epoch: 031/100 cost: 0.067545191 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.988\n",
      "time: 211.1694757938385\n",
      "Epoch: 032/100 cost: 0.065411880 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.988\n",
      "time: 211.9707169532776\n",
      "Epoch: 033/100 cost: 0.065556344 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.980\n",
      "time: 207.66071367263794\n",
      "Epoch: 034/100 cost: 0.066914776 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.977\n",
      "time: 212.5105106830597\n",
      "Epoch: 035/100 cost: 0.066591930 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
      "time: 210.9556212425232\n",
      "Epoch: 036/100 cost: 0.064039003 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.977\n",
      "time: 206.73875308036804\n",
      "Epoch: 037/100 cost: 0.064956985 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.988\n",
      "time: 212.28443717956543\n",
      "Epoch: 038/100 cost: 0.063470821 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.992\n",
      "time: 213.49778056144714\n",
      "Epoch: 039/100 cost: 0.064374059 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.984\n",
      "time: 212.19487857818604\n",
      "Epoch: 040/100 cost: 0.063484111 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.977\n",
      "time: 212.80780839920044\n",
      "Epoch: 041/100 cost: 0.063757063 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.969\n",
      "time: 206.54262161254883\n",
      "Epoch: 042/100 cost: 0.061162736 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
      "time: 203.61780762672424\n",
      "Epoch: 043/100 cost: 0.062641827 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.973\n",
      "time: 203.87435340881348\n",
      "Epoch: 044/100 cost: 0.061399529 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.973\n",
      "time: 213.18251419067383\n",
      "Epoch: 045/100 cost: 0.060782563 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.973\n",
      "time: 207.70540189743042\n",
      "Epoch: 046/100 cost: 0.062180294 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.973\n",
      "time: 213.27762150764465\n",
      "Epoch: 047/100 cost: 0.064557106 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.961\n",
      "time: 213.5227406024933\n",
      "Epoch: 048/100 cost: 0.064540147 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
      "time: 213.64682984352112\n",
      "Epoch: 049/100 cost: 0.065964876 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.988\n",
      "time: 211.51441049575806\n",
      "Epoch: 050/100 cost: 0.063422819 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
      "time: 211.5604932308197\n",
      "Epoch: 051/100 cost: 0.064402140 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.992\n",
      "time: 211.29727005958557\n",
      "Epoch: 052/100 cost: 0.064817948 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.996\n",
      "time: 212.42052745819092\n",
      "Epoch: 053/100 cost: 0.063098750 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.980\n",
      "time: 210.51476049423218\n",
      "Epoch: 054/100 cost: 0.063108727 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
      "time: 210.13550662994385\n",
      "Epoch: 055/100 cost: 0.062545386 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.984\n",
      "time: 210.27064895629883\n",
      "Epoch: 056/100 cost: 0.062096139 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
      "time: 214.0295763015747\n",
      "Epoch: 057/100 cost: 0.060786224 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
      "time: 216.4648756980896\n",
      "Epoch: 058/100 cost: 0.061742086 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.984\n",
      "time: 216.35612797737122\n",
      "Epoch: 059/100 cost: 0.062625588 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
      "time: 214.498717546463\n",
      "Epoch: 060/100 cost: 0.060654903 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
      "time: 214.60047268867493\n",
      "Epoch: 061/100 cost: 0.061439842 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
      "time: 212.51903915405273\n",
      "Epoch: 062/100 cost: 0.059980881 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.992\n",
      "time: 215.04228329658508\n",
      "Epoch: 063/100 cost: 0.059579929 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.980\n",
      "time: 215.68850255012512\n",
      "Epoch: 064/100 cost: 0.063064454 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
      "time: 207.25260376930237\n",
      "Epoch: 065/100 cost: 0.062576147 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.996\n",
      "time: 212.87481117248535\n",
      "Epoch: 066/100 cost: 0.061208351 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.980\n",
      "time: 212.7653148174286\n",
      "Epoch: 067/100 cost: 0.059519775 TRAIN ACCURACY: 1.000 TEST ACCURACY: 1.000\n",
      "time: 213.74839448928833\n",
      "Epoch: 068/100 cost: 0.061465173 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.992\n",
      "time: 211.33532524108887\n",
      "Epoch: 069/100 cost: 0.062106676 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.980\n",
      "time: 209.3124532699585\n",
      "Epoch: 070/100 cost: 0.063305255 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
      "time: 208.88017630577087\n",
      "Epoch: 071/100 cost: 0.061771334 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.977\n",
      "time: 209.55925178527832\n",
      "Epoch: 072/100 cost: 0.062125964 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.973\n",
      "time: 209.56863069534302\n",
      "Epoch: 073/100 cost: 0.059570560 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
      "time: 208.45188307762146\n",
      "Epoch: 074/100 cost: 0.060772701 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
      "time: 209.75778079032898\n",
      "Epoch: 075/100 cost: 0.063128881 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.965\n",
      "time: 210.34135222434998\n",
      "Epoch: 076/100 cost: 0.062430261 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.973\n",
      "time: 210.24310994148254\n",
      "Epoch: 077/100 cost: 0.059116414 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.965\n",
      "time: 208.7368779182434\n",
      "Epoch: 078/100 cost: 0.058827964 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.980\n",
      "time: 209.1994013786316\n",
      "Epoch: 079/100 cost: 0.061254471 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.977\n",
      "time: 209.66769814491272\n",
      "Epoch: 080/100 cost: 0.061604624 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
      "time: 211.07262587547302\n",
      "Epoch: 081/100 cost: 0.058273322 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
      "time: 209.8483145236969\n",
      "Epoch: 082/100 cost: 0.058319201 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.996\n",
      "time: 210.03093647956848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 083/100 cost: 0.060408494 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.969\n",
      "time: 210.42275738716125\n",
      "Epoch: 084/100 cost: 0.060326875 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.988\n",
      "time: 211.099134683609\n",
      "Epoch: 085/100 cost: 0.061545057 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
      "time: 211.01108503341675\n",
      "Epoch: 086/100 cost: 0.059381756 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.984\n",
      "time: 210.6314172744751\n",
      "Epoch: 087/100 cost: 0.061278177 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.984\n",
      "time: 209.16399335861206\n",
      "Epoch: 088/100 cost: 0.059857864 TRAIN ACCURACY: 0.985 TEST ACCURACY: 0.984\n",
      "time: 211.53392100334167\n",
      "Epoch: 089/100 cost: 0.059848712 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.984\n",
      "time: 204.77457308769226\n",
      "Epoch: 090/100 cost: 0.062242943 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.980\n",
      "time: 200.414067029953\n",
      "Epoch: 091/100 cost: 0.061534185 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
      "time: 206.11535048484802\n",
      "Epoch: 092/100 cost: 0.063804752 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.992\n",
      "time: 215.11330199241638\n",
      "Epoch: 093/100 cost: 0.062853724 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.984\n",
      "time: 212.44652676582336\n",
      "Epoch: 094/100 cost: 0.062241228 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.988\n",
      "time: 199.79515647888184\n",
      "Epoch: 095/100 cost: 0.058984535 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.988\n",
      "time: 204.05297803878784\n",
      "Epoch: 096/100 cost: 0.058647259 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
      "time: 205.99931931495667\n",
      "Epoch: 097/100 cost: 0.060636134 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.977\n",
      "time: 206.5321180820465\n",
      "Epoch: 098/100 cost: 0.059484073 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.984\n",
      "time: 209.73324728012085\n",
      "Epoch: 099/100 cost: 0.060713352 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.984\n",
      "time: 211.6835446357727\n",
      "Epoch: 100/100 cost: 0.058843817 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.992\n",
      "time: 211.1917130947113\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for i in range(100):\n",
    "        t1 = time.time()\n",
    "        avg_cost = 0.\n",
    "        train_batch = zip(range(0,len(trX),batch_size),\n",
    "                         range(batch_size,len(trX)+1,batch_size))\n",
    "        for start ,end in train_batch:\n",
    "            sess.run(optm,feed_dict={x:trX[start:end],y:trY[start:end],\n",
    "                                    p_keep_conv:0.8,p_keep_hidden:0.5})\n",
    "            avg_cost += sess.run(cost, feed_dict={x:trX[start:end],y:trY[start:end],\n",
    "                                                  p_keep_conv: 0.8,p_keep_hidden: 0.5})/(len(trX)/batch_size)\n",
    "        test_indices = np.arange(len(teX))\n",
    "        np.random.shuffle(test_indices)\n",
    "        test_indices = test_indices[0:test_size]\n",
    "        train_acc = sess.run(accr, feed_dict={x:trX[start:end],y:trY[start:end],\n",
    "                                              p_keep_conv:0.8,p_keep_hidden:0.5})\n",
    "        test_acc = sess.run(accr, feed_dict={x: teX[test_indices], y: teY[test_indices],\n",
    "                                             p_keep_conv:0.8,p_keep_hidden:0.5})\n",
    "        print(\"Epoch: %03d/%03d cost: %.9f TRAIN ACCURACY: %.3f TEST ACCURACY: %.3f\"\n",
    "              % (i+1, 100, avg_cost, train_acc, test_acc))\n",
    "        \n",
    "        t2=time.time()\n",
    "        print(\"time:\",t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* notebook上只跑了上述的代码，其他的参数尝试在tinymind上跑\n",
    "\n",
    "**三层卷积情况下**\n",
    "   * 高斯分布分布初始化参数\n",
    "   * 三层卷积，卷积核第一层是5,5（想让第一层的感受野大一些），后面两层是3,3，步长1，通道数为16,32,64，准确率在0.98多一点，通道数增大为32，64,128，卷积核全部是3*3准确率提高\n",
    "   * 最大池化，2*2，步长2， \n",
    "   * 全连接用了一个隐层625，\n",
    "   * 优化器用SGD时，学习率0.01，收敛很慢，后来用了收敛快的RMSPropOptimizer，学习率0.001，收敛很快，最后尝试了AdamOptimizer优化器，学习率0.001，速度很快，AdamOptimizer在tinymind上跑的最后几个结果，准确率波动，需要增大epoch\n",
    "   \n",
    "Epoch: 297/300 cost: 0.060344678 TRAIN ACCURACY: 0.995 TEST ACCURACY: 1.000\n",
    "\n",
    "time: 16.008718490600586\n",
    "\n",
    "Epoch: 298/300 cost: 0.061144738 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.977\n",
    "\n",
    "time: 15.982921838760376\n",
    "\n",
    "Epoch: 299/300 cost: 0.061210946 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.984\n",
    "\n",
    "time: 15.960307836532593\n",
    "\n",
    "Epoch: 300/300 cost: 0.059880949 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.992\n",
    "\n",
    "time: 15.990186214447021\n",
    "\n",
    "   * 激活函数用有自归一化的selu，后来换了relu，差别不大\n",
    "   * L2正则，256，正则参数为1/5000\n",
    "   * dropout，卷积保留0.8，全连接保留0.5，dropout，都是0.5，差别不大\n",
    "   \n",
    "**尝试四层卷积**\n",
    "  * 加一层卷积使输出变成向量 N,1,1,512，\n",
    "  * 'w4': init_weights([4,4,256,512]),\n",
    "   * l4a = tf.nn.relu(tf.nn.conv2d(l3,weights['w4'],strides=[1,1,1,1],padding = 'VALID')+biases['b4'])\n",
    "\n",
    "在tinymind上跑的结果\n",
    "\n",
    "Epoch: 296/300 cost: 0.031862083 TRAIN ACCURACY: 0.995 TEST ACCURACY: 1.000\n",
    "\n",
    "time: 14.93062710762024\n",
    "\n",
    "Epoch: 297/300 cost: 0.030513806 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.980\n",
    "\n",
    "time: 14.937577724456787\n",
    "\n",
    "Epoch: 298/300 cost: 0.034182577 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.988\n",
    "\n",
    "time: 14.927863597869873\n",
    "\n",
    "Epoch: 299/300 cost: 0.030758767 TRAIN ACCURACY: 0.990 TEST ACCURACY: 0.988\n",
    "\n",
    "time: 14.933849334716797\n",
    "\n",
    "Epoch: 300/300 cost: 0.030601733 TRAIN ACCURACY: 0.995 TEST ACCURACY: 0.992\n",
    "\n",
    "time: 14.929622888565063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
