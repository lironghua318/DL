{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mnist-多层感知机**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)#读取数据\n",
    "#mnist.train.images是一个55000 * 784维的矩阵, mnist.train.labels是一个55000 * 10维的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 512\n",
    "n_hidden_2 = 256\n",
    "n_input    = 784\n",
    "n_classes  = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS AND OUTPUTS\n",
    "x = tf.placeholder(tf.float32, [None, n_input]) # 用placeholder先占地方，样本个数不确定为None\n",
    "y = tf.placeholder(tf.float32, [None, n_classes]) # 用placeholder先占地方，样本个数不确定为None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK READY\n"
     ]
    }
   ],
   "source": [
    "# w1=tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev=0.1))\n",
    "# w2=tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=0.1))\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=1.0 / 5000)\n",
    "w1 = tf.get_variable(\n",
    "        name=\"w1\",\n",
    "        regularizer=regularizer,\n",
    "        initializer=tf.random_normal([n_input, n_hidden_1], stddev=0.1))\n",
    "w2 = tf.get_variable(\n",
    "        name=\"w2\",\n",
    "        regularizer=regularizer,\n",
    "        initializer=tf.random_normal([n_hidden_1, n_hidden_2], stddev=0.1))  \n",
    "weights = {\n",
    "    'w1': w1,#按照高斯分布初始化权重\n",
    "    'w2': w2,\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes],stddev=0.1))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.zeros([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes],stddev=0.1))\n",
    "}\n",
    "print(\"NETWORK READY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w1:0' shape=(784, 512) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "print(w1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加入L2正则**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.add_to_collection(tf.GraphKeys.WEIGHTS,w1)\n",
    "tf.add_to_collection(tf.GraphKeys.WEIGHTS,w2)\n",
    "# regularizer = tf.contrib.layers.l2_regularizer(scale=1.0 / 50000)\n",
    "# print(regularizer)\n",
    "reg_term = tf.contrib.layers.apply_regularization(regularizer)\n",
    "\n",
    "# loss = (tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_, logits=z_3)) +\n",
    "#         reg_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**隐层的激活函数尝试用RELU，输出层用softmax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-0de52eb79c3d>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "FUNCTIONS READY\n"
     ]
    }
   ],
   "source": [
    "def multilayer_perceptron(_X, _weights, _biases): # 前向传播，隐层用relu激活函数\n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(_X, _weights['w1']), _biases['b1'])) # 隐层\n",
    "    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, _weights['w2']), _biases['b2']))\n",
    "    return (tf.matmul(layer_2, _weights['out']) + _biases['out']) # 返回输出层的结果，得到十个类别的得分值\n",
    "\n",
    "pred = multilayer_perceptron(x, weights, biases) # 前向传播的预测值\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)+ reg_term) # 交叉熵损失函数，参数分别为预测值pred和实际label值y，reduce_mean为求平均loss\n",
    "optm = tf.train.GradientDescentOptimizer(0.3).minimize(cost) # 梯度下降优化器\n",
    "corr = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1)) # tf.equal()对比预测值的索引和实际label的索引是否一样，一样返回True，不一样返回False\n",
    "accr = tf.reduce_mean(tf.cast(corr, tf.float32)) # 将pred即True或False转换为1或0,并对所有的判断结果求均值\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "print(\"FUNCTIONS READY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上面神经网络结构定义好之后，下面定义一些超参数\n",
    "training_epochs = 100 # 所有样本迭代100次\n",
    "batch_size = 100 # 每进行一次迭代选择100个样本\n",
    "display_step = 5\n",
    "# LAUNCH THE GRAPH\n",
    "sess = tf.Session() # 定义一个Session\n",
    "sess.run(init) # 在sess里run一下初始化操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/100 cost: 0.654845242 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.951\n",
      "Epoch: 005/100 cost: 0.390731738 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.980\n",
      "Epoch: 010/100 cost: 0.286465457 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.981\n",
      "Epoch: 015/100 cost: 0.210895940 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.983\n",
      "Epoch: 020/100 cost: 0.190913507 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.973\n",
      "Epoch: 025/100 cost: 0.164551673 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.973\n",
      "Epoch: 030/100 cost: 0.097010477 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.984\n",
      "Epoch: 035/100 cost: 0.073419419 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.984\n",
      "Epoch: 040/100 cost: 0.065583655 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.982\n",
      "Epoch: 045/100 cost: 0.050287199 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.984\n",
      "Epoch: 050/100 cost: 0.060373035 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.980\n",
      "Epoch: 055/100 cost: 0.047307676 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.981\n",
      "Epoch: 060/100 cost: 0.036814879 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.984\n",
      "Epoch: 065/100 cost: 0.029645635 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.984\n",
      "Epoch: 070/100 cost: 0.076851208 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.978\n",
      "Epoch: 075/100 cost: 0.060936313 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.980\n",
      "Epoch: 080/100 cost: 0.046611791 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.984\n",
      "Epoch: 085/100 cost: 0.038153145 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.972\n",
      "Epoch: 090/100 cost: 0.034924216 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.983\n",
      "Epoch: 095/100 cost: 0.027234120 TRAIN ACCURACY: 1.000 TEST ACCURACY: 0.984\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size) # 逐个batch的去取数据\n",
    "        sess.run(optm, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys})/total_batch\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        train_acc = sess.run(accr, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        test_acc = sess.run(accr, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Epoch: %03d/%03d cost: %.9f TRAIN ACCURACY: %.3f TEST ACCURACY: %.3f\"\n",
    "              % (epoch, training_epochs, avg_cost, train_acc, test_acc))\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**一层隐层情况下**\n",
    "   * 神经元，256，在调整学习率时，设置为0.01，最后训练准确率达到0.97，试着将学习率增大为0.5，准确率最后是0.982，有提高\n",
    "   * 神经元，512，学习率，0.3，准确率，0.983，增加神经元后性能稍有改善\n",
    "   \n",
    "**两层隐层情况下**\n",
    "   * 两个隐层神经元都设置为256，学习率0.3，最后训练准确率0.981，增加隐层后性能反而略有下降\n",
    "   * 隐层输入权重w初始化为高斯分布，尝试将输出层的权重也初始化为高斯分布,准确率为0.981，在训练集上很早就达到了1的准确率，测试集效果却一直没有提升，可能存在过拟合，尝试加入正则\n",
    "   * 加入正则试试看，加入L2正则,准确率0.982，增加第一层的神经元为512，准确率为0.983\n",
    "   * 尝试调节正则项的参数，scale=5.0 / 50000，改为scale=1.0 / 50000，准确率为0.983，准确率没有提升，但是较快到达了0.983的准确率\n",
    "\n",
    "**上面尝试的是relu激活函数，下面试试tanh** \n",
    "   * 在两个隐层都是256情况下，准确率最后达到了0.980，效果没有relu激活函数好\n",
    "   \n",
    "**最后代码用两个隐层，激活函数用relu，神经元数第一层512第二层256，学习率0.3，加大惩罚，L2正则参数scale=1.0 / 5000，得出准确率为0.984**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
